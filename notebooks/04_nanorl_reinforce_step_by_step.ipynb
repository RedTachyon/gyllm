{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cfc30f6",
   "metadata": {},
   "source": [
    "# NanoRL REINFORCE training loop (step-by-step)\n",
    "\n",
    "This notebook mirrors the training script with explicit steps per cell.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5e26b7",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa378eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from vllm import SamplingParams\n",
    "\n",
    "import gyllm\n",
    "from gyllm.envs import AutoResetWrapper\n",
    "from nanorl.agent import InstructAgent\n",
    "from nanorl.rl import compute_reinforce_loss\n",
    "from nanorl.rollout import NanoLLM\n",
    "from nanorl.rollout.reporting import summarize_rollouts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9241edf8",
   "metadata": {},
   "source": [
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e101687",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "num_envs = 2\n",
    "episodes = 4\n",
    "num_updates = 3\n",
    "minibatch_size = 2\n",
    "lr = 1e-5\n",
    "max_grad_norm = 1.0\n",
    "temperature = 1.0\n",
    "max_tokens = 128\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ced443",
   "metadata": {},
   "source": [
    "## Model and NanoLLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b7b842",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    dtype=\"bfloat16\",\n",
    "    device_map=\"cuda\",\n",
    ")\n",
    "llm = NanoLLM(\n",
    "    model,\n",
    "    tokenizer=tokenizer,\n",
    "    gpu_memory_utilization=0.4,\n",
    "    enable_sleep_mode=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edb9986",
   "metadata": {},
   "source": [
    "## Environment and agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3beefcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gyllm.make(\n",
    "    \"simple/reverse_echo\",\n",
    "    env_kwargs={\"num_turns\": 2},\n",
    "    num_envs=num_envs,\n",
    ")\n",
    "env = AutoResetWrapper(env)\n",
    "\n",
    "sampling_params = SamplingParams(temperature=temperature, max_tokens=max_tokens)\n",
    "agent = InstructAgent(\n",
    "    model=model,\n",
    "    llm=llm,\n",
    "    tokenizer=tokenizer,\n",
    "    sampling_params=sampling_params,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f137d6e",
   "metadata": {},
   "source": [
    "## Optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50006818",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f834a7",
   "metadata": {},
   "source": [
    "## Training loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88b6410",
   "metadata": {},
   "outputs": [],
   "source": [
    "for update in range(num_updates):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        llm.wake_up()\n",
    "        rollouts = agent.rollout_autoreset_batched(\n",
    "            env,\n",
    "            max_episodes=episodes,\n",
    "        )\n",
    "    llm.sleep(1)\n",
    "\n",
    "    _tokens, mean_reward, _sample_text = summarize_rollouts(rollouts, tokenizer)\n",
    "\n",
    "    model.train()\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    total_rollouts = len(rollouts)\n",
    "    if total_rollouts == 0:\n",
    "        print(f\"update={update} skipped (no rollouts)\")\n",
    "        continue\n",
    "\n",
    "    total_loss_value = 0.0\n",
    "    total_assistant_tokens = 0.0\n",
    "    total_logprob = 0.0\n",
    "    reward_sum = 0.0\n",
    "\n",
    "    for start in range(0, total_rollouts, minibatch_size):\n",
    "        minibatch = rollouts[start : start + minibatch_size]\n",
    "        loss, mb_metrics = compute_reinforce_loss(\n",
    "            minibatch,\n",
    "            model,\n",
    "            tokenizer,\n",
    "            device=next(model.parameters()).device,\n",
    "        )\n",
    "        mb_size = len(minibatch)\n",
    "        reward_sum += mb_metrics[\"avg_reward\"] * mb_size\n",
    "        total_assistant_tokens += mb_metrics[\"assistant_tokens\"]\n",
    "        total_logprob += mb_metrics[\"avg_logprob\"] * mb_metrics[\"assistant_tokens\"]\n",
    "\n",
    "        if mb_metrics[\"assistant_tokens\"] <= 0:\n",
    "            continue\n",
    "\n",
    "        scale = mb_size / total_rollouts\n",
    "        (loss * scale).backward()\n",
    "        total_loss_value += float(loss.item()) * scale\n",
    "\n",
    "    if total_assistant_tokens == 0:\n",
    "        print(f\"update={update} skipped (no assistant tokens)\")\n",
    "        continue\n",
    "\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "    optimizer.step()\n",
    "\n",
    "    avg_reward = reward_sum / total_rollouts\n",
    "    avg_logprob = total_logprob / total_assistant_tokens\n",
    "    print(\n",
    "        f\"update={update} loss={total_loss_value:.4f} avg_reward={avg_reward:.3f} \"\n",
    "        f\"avg_logprob={avg_logprob:.3f}\"\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
