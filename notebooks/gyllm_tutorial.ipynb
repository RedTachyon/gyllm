{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f41367b1",
   "metadata": {},
   "source": [
    "# GYLLM Tutorial\n",
    "\n",
    "Overview of the `gyllm` environment API:\n",
    "- Core types: `LLMEnv`, `Request`, `ActorId`\n",
    "- Episode loops with per-actor chat histories\n",
    "- Multi-agent and batched envs\n",
    "- Subprocess and Docker hosting\n",
    "\n",
    "Requirements: `gyllm` importable in the kernel (e.g. `uv sync` or `uv pip install -e packages/gyllm`).\n",
    "\n",
    "Conventions:\n",
    "- histories are `system` -> `user` -> `assistant` -> ...\n",
    "- env responses use role `\"user\"`\n",
    "- actions use role `\"assistant\"`\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "de2f814b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T16:33:35.420677917Z",
     "start_time": "2025-12-22T16:33:35.412935564Z"
    }
   },
   "source": [
    "\n",
    "import ast\n",
    "import re\n",
    "from contextlib import ExitStack\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Callable\n",
    "\n",
    "import gyllm  # noqa: F401\n",
    "\n",
    "print(\"gyllm import OK\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gyllm import OK\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "0bb0e226",
   "metadata": {},
   "source": [
    "## 0) Imports\n",
    "\n",
    "`make()` uses the registry; `batch_envs()` combines env instances.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "230794cd",
   "metadata": {
    "lines_to_next_cell": 1,
    "ExecuteTime": {
     "end_time": "2025-12-22T16:33:37.455678428Z",
     "start_time": "2025-12-22T16:33:37.444836580Z"
    }
   },
   "source": [
    "from gyllm import list_envs, make\n",
    "from gyllm.batch import batch_envs\n",
    "from gyllm.core import ActorId, LLMEnv, Message, Request, actor_agent, make_actor_id\n",
    "from gyllm.envs.simple.iterated_games import TftIpdEnv"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "292e60fa",
   "metadata": {},
   "source": [
    "## 1) Actors and requests\n",
    "\n",
    "Actors are identified by strings like `\"agent\"` or `\"agent::env=3\"`.\n",
    "Each step returns `Request` objects:\n",
    "- `actor`, `reward`, `message`, `needs_action`\n",
    "- episode metadata: `episode_id`, `episode_start`, `episode_end`\n",
    "\n",
    "The env returns only the next message; histories are maintained by the caller.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "7e115ee2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T16:39:17.142267299Z",
     "start_time": "2025-12-22T16:39:17.124573836Z"
    }
   },
   "source": [
    "def show_requests(requests: list[Request], *, title: str | None = None) -> None:\n",
    "    if title:\n",
    "        print(title)\n",
    "        print(\"-\" * len(title))\n",
    "    for r in requests:\n",
    "        actor = r[\"actor\"]\n",
    "        msg = r[\"message\"]\n",
    "        preview = msg[\"content\"].replace(\"\\n\", \"\\\\n\")\n",
    "        if len(preview) > 100:\n",
    "            preview = preview[:100] + \"...\"\n",
    "        print(\n",
    "            f\"actor={actor} episode={r['episode_id']} start={r['episode_start']} \"\n",
    "            f\"end={r['episode_end']} needs_action={r['needs_action']} reward={r['reward']:.3f} \"\n",
    "            f\"| message.role={msg['role']!r} message={preview!r}\"\n",
    "        )\n",
    "\n",
    "\n",
    "# Preferred: instantiate via the registry.\n",
    "env = gyllm.make(\"openenv/echo\")\n",
    "requests = env.reset()\n",
    "show_requests(requests, title=\"make('openenv/echo').reset()\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make('openenv/echo').reset()\n",
      "---------------------------------\n",
      "actor=agent episode=0 start=True end=False needs_action=True reward=0.000 | message.role='user' message='Echo environment ready. Send a message.'\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "36573ea4",
   "metadata": {},
   "source": [
    "## 2) Single-agent loop (manual history)\n",
    "\n",
    "Maintain history locally:\n",
    "- start with `request[\"system_message\"]` on episode start (`system`)\n",
    "- append env messages (`user`)\n",
    "- append actions (`assistant`)\n",
    "\n",
    "Action formatting is env-specific.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "dac27fc7",
   "metadata": {
    "lines_to_next_cell": 1,
    "ExecuteTime": {
     "end_time": "2025-12-22T16:39:08.228470074Z",
     "start_time": "2025-12-22T16:39:08.220715552Z"
    }
   },
   "source": [
    "env = make(\"openenv/echo\")\n",
    "actor: ActorId = make_actor_id(\"agent\")\n",
    "\n",
    "requests = env.reset()\n",
    "history: list[Message] = [requests[0][\"system_message\"], requests[0][\"message\"]]\n",
    "\n",
    "print(\"System message role:\", history[0][\"role\"])\n",
    "print(\"First env message role:\", history[1][\"role\"])\n",
    "print(\"First env message:\", history[1][\"content\"])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System message role: system\n",
      "First env message role: user\n",
      "First env message: Echo environment ready. Send a message.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39b2eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def echo_policy(messages: list[Message], *, turn: int) -> str:\n",
    "    # Minimal \"agent\": say something different each time.\n",
    "    return f\"hello from turn={turn}\"\n",
    "\n",
    "\n",
    "total_reward = 0.0\n",
    "max_turns = 3\n",
    "\n",
    "for turn in range(1, max_turns + 1):\n",
    "    pending = [r for r in requests if r[\"needs_action\"]]\n",
    "    if not pending:\n",
    "        break\n",
    "\n",
    "    completion = echo_policy(history, turn=turn)\n",
    "    history.append({\"role\": \"assistant\", \"content\": completion})\n",
    "\n",
    "    requests = env.step({actor: completion})\n",
    "    if not requests:\n",
    "        break\n",
    "\n",
    "    total_reward += requests[0][\"reward\"]\n",
    "    history.append(requests[0][\"message\"])\n",
    "\n",
    "    print(f\"turn={turn} reward={requests[0]['reward']:.3f} env says: {requests[0]['message']['content']!r}\")\n",
    "\n",
    "    if not requests[0][\"needs_action\"]:\n",
    "        break\n",
    "\n",
    "print(\"total_reward:\", total_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5aabfcb",
   "metadata": {},
   "source": [
    "## 3) Reusable episode runner\n",
    "\n",
    "Works for single-agent, multi-agent, batched, and remote envs. The only change is the number of actors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd0dc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "Policy = Callable[[ActorId, list[Message]], str]\n",
    "\n",
    "\n",
    "@dataclass(slots=True)\n",
    "class EpisodeResult:\n",
    "    histories: dict[ActorId, list[Message]]\n",
    "    total_reward: dict[ActorId, float]\n",
    "    steps: int\n",
    "\n",
    "\n",
    "def run_episode(\n",
    "    env: LLMEnv,\n",
    "    *,\n",
    "    policy: Policy,\n",
    "    max_steps: int = 50,\n",
    "    verbose: bool = False,\n",
    ") -> EpisodeResult:\n",
    "    histories: dict[ActorId, list[Message]] = {}\n",
    "    totals: dict[ActorId, float] = {}\n",
    "\n",
    "    requests = env.reset()\n",
    "    for req in requests:\n",
    "        histories[req[\"actor\"]] = [req[\"system_message\"], req[\"message\"]]\n",
    "        totals[req[\"actor\"]] = float(req[\"reward\"])\n",
    "\n",
    "    if verbose:\n",
    "        show_requests(requests, title=\"reset() -> requests\")\n",
    "\n",
    "    steps = 0\n",
    "    while steps < max_steps:\n",
    "        pending = [r[\"actor\"] for r in requests if r[\"needs_action\"]]\n",
    "        if not pending:\n",
    "            break\n",
    "\n",
    "        actions: dict[ActorId, str] = {}\n",
    "        for actor in pending:\n",
    "            completion = policy(actor, histories[actor])\n",
    "            actions[actor] = completion\n",
    "            histories[actor].append({\"role\": \"assistant\", \"content\": completion})\n",
    "\n",
    "        requests = env.step(actions)\n",
    "        if not requests:\n",
    "            break\n",
    "\n",
    "        for req in requests:\n",
    "            histories.setdefault(req[\"actor\"], []).append(req[\"message\"])\n",
    "            totals.setdefault(req[\"actor\"], 0.0)\n",
    "            totals[req[\"actor\"]] += float(req[\"reward\"])\n",
    "\n",
    "        if verbose:\n",
    "            show_requests(requests, title=f\"step={steps + 1} -> requests\")\n",
    "\n",
    "        steps += 1\n",
    "\n",
    "    return EpisodeResult(histories=histories, total_reward=totals, steps=steps)\n",
    "\n",
    "\n",
    "res = run_episode(make(\"openenv/echo\"), policy=lambda _actor, _msgs: \"hi\", max_steps=3, verbose=True)\n",
    "print(\"steps:\", res.steps)\n",
    "print(\"total_reward:\", res.total_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d46717",
   "metadata": {},
   "source": [
    "## 2a) Registry and direct instantiation\n",
    "\n",
    "Use `make(...)` for registry-based envs; direct class construction is also supported.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f72bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Some registered envs:\", list_envs()[:8])\n",
    "\n",
    "# Preferred:\n",
    "env = make(\"simple/tft_ipd\", env_kwargs={\"num_turns\": 2})\n",
    "\n",
    "# Direct construction (still supported):\n",
    "direct_env = TftIpdEnv(num_turns=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c114a17",
   "metadata": {},
   "source": [
    "## 4) Multi-agent example: Connect4\n",
    "\n",
    "The env exposes multiple actors and uses `needs_action` to indicate whose turn it is.\n",
    "This policy parses `Legal actions: [...]` and picks the first legal column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a5bb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "_LEGAL_ACTIONS_RE = re.compile(r\"Legal actions:\\s*(\\[[^\\]]*\\])\")\n",
    "\n",
    "\n",
    "def parse_legal_actions_from_text(text: str) -> list[int]:\n",
    "    m = _LEGAL_ACTIONS_RE.search(text)\n",
    "    if not m:\n",
    "        raise ValueError(\"Expected 'Legal actions: [...]' in the last env message.\")\n",
    "    value = ast.literal_eval(m.group(1))\n",
    "    if not isinstance(value, list) or not all(isinstance(x, int) for x in value):\n",
    "        raise ValueError(f\"Could not parse legal actions from: {m.group(1)!r}\")\n",
    "    return value\n",
    "\n",
    "\n",
    "def connect4_policy(_actor: ActorId, messages: list[Message]) -> str:\n",
    "    legal = parse_legal_actions_from_text(messages[-1][\"content\"])\n",
    "    return str(legal[0])\n",
    "\n",
    "\n",
    "env = make(\"openenv/connect4\", env_kwargs={\"opponent\": None})\n",
    "res = run_episode(env, policy=connect4_policy, max_steps=8, verbose=False)\n",
    "\n",
    "print(\"actors:\", sorted(res.histories.keys()))\n",
    "print(\"steps:\", res.steps)\n",
    "for actor, total in sorted(res.total_reward.items()):\n",
    "    print(actor, \"total_reward:\", total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605d4b7d",
   "metadata": {},
   "source": [
    "## 5) Vectorization: many worlds, same API\n",
    "\n",
    "`make(..., num_envs=N)` returns a batched env. Use `autoreset=True` to restart completed envs.\n",
    "Actor ids include `env=` metadata (e.g. `agent::env=1`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2a8cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "venv = make(\"simple/tft_ipd\", env_kwargs={\"num_turns\": 2}, num_envs=4, autoreset=True)\n",
    "\n",
    "\n",
    "def ipd_policy(_actor: ActorId, _messages: list[Message]) -> str:\n",
    "    # Always cooperate.\n",
    "    return \"<action>A</action>\"\n",
    "\n",
    "\n",
    "res = run_episode(venv, policy=ipd_policy, max_steps=5, verbose=False)\n",
    "\n",
    "print(\"num_actors:\", len(res.histories))\n",
    "print(\"actors:\", sorted(res.histories.keys())[:6], \"...\" if len(res.histories) > 6 else \"\")\n",
    "print(\"steps:\", res.steps)\n",
    "print(\"total_reward_by_actor:\", {k: round(v, 3) for k, v in sorted(res.total_reward.items())})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3c3280",
   "metadata": {},
   "source": [
    "### 5b) Vectorized + multi-agent\n",
    "\n",
    "Two env instances with two agents each produce four actors:\n",
    "`\"player_a::env=0\"`, `\"player_b::env=0\"`, `\"player_a::env=1\"`, `\"player_b::env=1\"`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2876aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "venv2 = make(\"openenv/connect4\", env_kwargs={\"opponent\": None}, num_envs=2, autoreset=True)\n",
    "res = run_episode(venv2, policy=connect4_policy, max_steps=6, verbose=False)\n",
    "\n",
    "print(\"actors:\", sorted(res.histories.keys()))\n",
    "print(\"steps:\", res.steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed19c348",
   "metadata": {},
   "source": [
    "### 5c) Batching heterogeneous envs\n",
    "\n",
    "`make(..., num_envs=N)` is the standard path. You can also batch explicit env instances,\n",
    "including mixed env types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854351b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed = batch_envs(\n",
    "    [\n",
    "        make(\"openenv/echo\"),\n",
    "        make(\"simple/tft_ipd\", env_kwargs={\"num_turns\": 1}),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def mixed_policy(actor: ActorId, _messages: list[Message]) -> str:\n",
    "    agent_id = actor_agent(actor)\n",
    "    if agent_id == \"agent\":\n",
    "        return \"hi\"\n",
    "    if agent_id == \"player\":\n",
    "        return \"<action>A</action>\"\n",
    "    raise KeyError(f\"Unknown agent_id: {agent_id!r}\")\n",
    "\n",
    "\n",
    "res = run_episode(mixed, policy=mixed_policy, max_steps=2)\n",
    "print(\"mixed actors:\", sorted(res.histories.keys()))\n",
    "print(\"mixed total_reward:\", {k: round(v, 3) for k, v in sorted(res.total_reward.items())})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90c2d07",
   "metadata": {},
   "source": [
    "## 6) Out-of-process hosting\n",
    "\n",
    "`make(..., mode=\"subprocess\")` runs `python -m gyllm.rpc_server ...`\n",
    "`make(..., mode=\"docker\")` runs `docker run ... python -m gyllm.rpc_server ...`\n",
    "\n",
    "The returned client implements the same API as an in-memory env.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dae3c2",
   "metadata": {},
   "source": [
    "### 6a) Subprocess-hosted env\n",
    "\n",
    "No image build required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5ffaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote = make(\n",
    "    \"openenv/echo\",\n",
    "    mode=\"subprocess\",\n",
    ")\n",
    "res = run_episode(remote, policy=lambda _a, _m: \"hello\", max_steps=2, verbose=True)\n",
    "remote.close()\n",
    "print(\"remote total_reward:\", res.total_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fb689e",
   "metadata": {},
   "source": [
    "### 6b) Docker-hosted env\n",
    "\n",
    "The container must be able to import `gyllm`. If you're using uv locally, build an\n",
    "image that installs `gyllm` (e.g. `uv pip install gyllm`) or mount the repo and set\n",
    "`PYTHONPATH` accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3ac337",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_DOCKER_DEMO = False  # set True to run\n",
    "\n",
    "if RUN_DOCKER_DEMO:\n",
    "    # This assumes you're running the notebook inside a container or VM with `/workspace` mounted\n",
    "    # and that the container has access to the docker daemon (/var/run/docker.sock).\n",
    "    #\n",
    "    # We reuse the current container's mounted volumes so the nested container can import `gyllm`\n",
    "    # from `/workspace/src` without needing a custom-built image.\n",
    "    container_id = Path(\"/etc/hostname\").read_text(encoding=\"utf-8\").strip()\n",
    "    remote = make(\n",
    "        \"openenv/echo\",\n",
    "        mode=\"docker\",\n",
    "        image=\"gyllm:dev\",\n",
    "        docker_args=[\n",
    "            \"--pull=never\",\n",
    "            \"--volumes-from\",\n",
    "            f\"{container_id}:ro\",\n",
    "            \"-w\",\n",
    "            \"/workspace\",\n",
    "            \"-e\",\n",
    "            \"PYTHONPATH=/workspace/src\",\n",
    "        ],\n",
    "    )\n",
    "    res = run_episode(remote, policy=lambda _a, _m: \"hi from docker\", max_steps=2)\n",
    "    remote.close()\n",
    "    print(\"docker total_reward:\", res.total_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edc15d7",
   "metadata": {},
   "source": [
    "### 6c) Vectorizing remote envs\n",
    "\n",
    "Host multiple envs and batch the clients with `batch_envs`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6290fb4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "with ExitStack() as stack:\n",
    "    envs = [\n",
    "        stack.enter_context(\n",
    "            make(\n",
    "                \"openenv/echo\",\n",
    "                mode=\"subprocess\",\n",
    "            )\n",
    "        )\n",
    "        for _ in range(3)\n",
    "    ]\n",
    "    vremote = batch_envs(envs)\n",
    "    res = run_episode(vremote, policy=lambda _a, _m: \"batched\", max_steps=2)\n",
    "    print(\"actors:\", sorted(res.histories.keys()))\n",
    "    print(\"total_reward:\", {k: round(v, 3) for k, v in sorted(res.total_reward.items())})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8b5e57",
   "metadata": {},
   "source": [
    "## 7) Writing an env\n",
    "\n",
    "Define `agents` and implement `_system_message()`, `reset()`, and `step()`.\n",
    "Env implementations set episode metadata on requests.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f943ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CounterEnv(LLMEnv):\n",
    "    agents = [\"agent\"]\n",
    "\n",
    "    def __init__(self, *, target: int = 3) -> None:\n",
    "        super().__init__()\n",
    "        self.target = int(target)\n",
    "        self.value = 0\n",
    "\n",
    "    def _system_message(self, actor: ActorId) -> Message:\n",
    "        agent = self.agent_id(actor)\n",
    "        if agent != \"agent\":\n",
    "            raise KeyError(f\"Unknown agent: {agent!r}\")\n",
    "        return {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are in CounterEnv.\\n\"\n",
    "                \"Each turn, increment the counter by sending `inc`.\\n\"\n",
    "                \"When the counter reaches the target, the episode ends.\"\n",
    "            ),\n",
    "        }\n",
    "\n",
    "    def reset(self, options: dict[str, object] | None = None) -> list[Request]:\n",
    "        self._begin_episode()\n",
    "        self.value = 0\n",
    "        requests = [\n",
    "            {\n",
    "                \"actor\": make_actor_id(\"agent\"),\n",
    "                \"reward\": 0.0,\n",
    "                \"system_message\": self._system_message(make_actor_id(\"agent\")),\n",
    "                \"message\": {\"role\": \"user\", \"content\": f\"Counter reset. value={self.value} target={self.target}\"},\n",
    "                \"needs_action\": True,\n",
    "            }\n",
    "        ]\n",
    "        for request in requests:\n",
    "            request[\"episode_id\"] = self._episode_id\n",
    "            request[\"episode_start\"] = True\n",
    "            request[\"episode_end\"] = False\n",
    "        return requests\n",
    "\n",
    "    def step(self, actions: dict[ActorId, str]) -> list[Request]:\n",
    "        actions = self._normalize_actions(actions)\n",
    "        action = actions[\"agent\"].strip().lower()\n",
    "        if action != \"inc\":\n",
    "            requests = [\n",
    "                {\n",
    "                    \"actor\": make_actor_id(\"agent\"),\n",
    "                    \"reward\": -1.0,\n",
    "                    \"message\": {\"role\": \"user\", \"content\": f\"Invalid action {action!r}. Expected 'inc'.\"},\n",
    "                    \"needs_action\": True,\n",
    "                }\n",
    "            ]\n",
    "            done = not requests or not any(r[\"needs_action\"] for r in requests)\n",
    "            for request in requests:\n",
    "                request[\"episode_id\"] = self._episode_id\n",
    "                request[\"episode_start\"] = False\n",
    "                request[\"episode_end\"] = bool(done)\n",
    "            return requests\n",
    "\n",
    "        self.value += 1\n",
    "        done = self.value >= self.target\n",
    "        reward = 1.0 if done else 0.0\n",
    "        requests = [\n",
    "            {\n",
    "                \"actor\": make_actor_id(\"agent\"),\n",
    "                \"reward\": reward,\n",
    "                \"message\": {\"role\": \"user\", \"content\": f\"value={self.value} done={done}\"},\n",
    "                \"needs_action\": not done,\n",
    "            }\n",
    "        ]\n",
    "        done = not requests or not any(r[\"needs_action\"] for r in requests)\n",
    "        for request in requests:\n",
    "            request[\"episode_id\"] = self._episode_id\n",
    "            request[\"episode_start\"] = False\n",
    "            request[\"episode_end\"] = bool(done)\n",
    "        return requests\n",
    "\n",
    "\n",
    "env = CounterEnv(target=3)\n",
    "res = run_episode(env, policy=lambda _a, _m: \"inc\", max_steps=10, verbose=True)\n",
    "print(\"total_reward:\", res.total_reward)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b02670",
   "metadata": {},
   "source": [
    "## 8) Summary\n",
    "\n",
    "- Actors unify single-agent, multi-agent, and batched usage.\n",
    "- `make(...)` works for local, batched, and out-of-process envs."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "py:percent,ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}