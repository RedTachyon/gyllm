{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f12b9420",
   "metadata": {},
   "source": [
    "# GYLLM env API demo (text-in / text-out)\n",
    "\n",
    "This notebook shows:\n",
    "- Using a text-based env directly (you maintain message history)\n",
    "- Using `TokenizedEnv` to convert text requests into token requests\n",
    "\n",
    "Prerequisite: `gyllm` should be importable in your notebook kernel (e.g. `pip install -e .`)."
   ]
  },
  {
   "cell_type": "code",
   "id": "04c47451",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T01:16:06.541644309Z",
     "start_time": "2025-12-21T01:16:06.535948395Z"
    }
   },
   "source": [
    "\n",
    "import gyllm  # noqa: F401"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc211c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gyllm.envs.simple.iterated_games import IpdEnv, TftIpdEnv\n",
    "from gyllm.batch import vectorize\n",
    "from gyllm.rpc import subprocess_env\n",
    "from gyllm.envs.tokenization import TokenizedEnv\n",
    "from gyllm.core import ActorId, actor_agent, make_actor_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fded62",
   "metadata": {},
   "source": [
    "## 1) Single-agent env (manual history)\n",
    "\n",
    "The env returns a `Request`:\n",
    "- `actor`: `(env_id, agent_id)`\n",
    "- `reward`: reward from the last transition\n",
    "- `message`: a single environment \"user\" message to append to your history\n",
    "- `needs_action`: whether the agent should respond next\n",
    "\n",
    "Note: action formatting is env-specific. `TftIpdEnv` expects actions in `<action>...</action>` tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3783552",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "env = TftIpdEnv(num_turns=3)\n",
    "player = make_actor_id(\"player\")\n",
    "\n",
    "requests = env.reset()\n",
    "\n",
    "req = requests[0]\n",
    "history: list[dict[str, str]] = [req[\"system_message\"], req[\"message\"]]\n",
    "\n",
    "print(\"actor:\", req[\"actor\"])\n",
    "print(\"needs_action:\", req[\"needs_action\"])\n",
    "print(\"last message:\", history[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86690920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_agent_policy(messages: list[dict[str, str]]) -> str:\n",
    "    # For demo purposes: always cooperate.\n",
    "    return \"<action>A</action>\"\n",
    "\n",
    "\n",
    "total_reward = 0.0\n",
    "\n",
    "while True:\n",
    "    action_text = simple_agent_policy(history)\n",
    "    actions = {player: action_text}\n",
    "\n",
    "    history.append({\"role\": \"assistant\", \"content\": action_text})\n",
    "\n",
    "    requests = env.step(actions)\n",
    "    if not requests:\n",
    "        break\n",
    "\n",
    "    req = requests[0]\n",
    "    total_reward += req[\"reward\"]\n",
    "\n",
    "    history.append(req[\"message\"])\n",
    "\n",
    "    print(\"reward:\", req[\"reward\"], \"| needs_action:\", req[\"needs_action\"])\n",
    "    print(\"env says:\", history[-1][\"content\"])\n",
    "\n",
    "    if not req[\"needs_action\"]:\n",
    "        break\n",
    "\n",
    "print(\"total_reward:\", total_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555bd53d",
   "metadata": {},
   "source": [
    "## 2) Two-agent env (separate histories per agent)\n",
    "\n",
    "`IpdEnv` returns one request per agent each step.\n",
    "Each agent gets its own private message stream (the env shares only actions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894b2a36",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "env2 = IpdEnv(num_turns=2)\n",
    "\n",
    "a = make_actor_id(\"player_a\")\n",
    "b = make_actor_id(\"player_b\")\n",
    "\n",
    "histories: dict[ActorId, list[dict[str, str]]] = {\n",
    "    a: [],\n",
    "    b: [],\n",
    "}\n",
    "requests = env2.reset()\n",
    "for req in requests:\n",
    "    histories[req[\"actor\"]] = [req[\"system_message\"], req[\"message\"]]\n",
    "\n",
    "\n",
    "def policy_a(messages: list[dict[str, str]]) -> str:\n",
    "    return \"<action>A</action>\"\n",
    "\n",
    "\n",
    "def policy_b(messages: list[dict[str, str]]) -> str:\n",
    "    return \"<action>B</action>\"\n",
    "\n",
    "\n",
    "totals = {\"player_a\": 0.0, \"player_b\": 0.0}\n",
    "\n",
    "while True:\n",
    "    actions = {a: policy_a(histories[a]), b: policy_b(histories[b])}\n",
    "\n",
    "    histories[a].append({\"role\": \"assistant\", \"content\": actions[a]})\n",
    "    histories[b].append({\"role\": \"assistant\", \"content\": actions[b]})\n",
    "\n",
    "    requests = env2.step(actions)\n",
    "    if not requests:\n",
    "        break\n",
    "\n",
    "    for req in requests:\n",
    "        agent_name = actor_agent(req[\"actor\"])\n",
    "        totals[agent_name] += req[\"reward\"]\n",
    "        histories[req[\"actor\"]].append(req[\"message\"])\n",
    "        print(req[\"actor\"], \"reward:\", req[\"reward\"], \"| last:\", histories[req[\"actor\"]][-1][\"content\"])\n",
    "\n",
    "    if all(not r[\"needs_action\"] for r in requests):\n",
    "        break\n",
    "\n",
    "print(\"totals:\", totals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cb5521",
   "metadata": {},
   "source": [
    "## 3) Tokenization on top (`TokenizedEnv`)\n",
    "\n",
    "`TokenizedEnv` wraps a text env and:\n",
    "- maintains per-agent histories internally\n",
    "- appends agent completions as `\"assistant\"` messages by default\n",
    "- returns `TokenRequest` objects with `prompt: list[int]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c4ebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_tokenize(messages: list[dict[str, str]], **kwargs) -> list[int]:\n",
    "    # Demo tokenizer: returns one \"token\" equal to total character count.\n",
    "    text = \"\".join(f\"{m['role']}:{m['content']}\\n\" for m in messages)\n",
    "    return [len(text)]\n",
    "\n",
    "\n",
    "wrapped = TokenizedEnv(TftIpdEnv(num_turns=2), tokenize=dummy_tokenize)\n",
    "\n",
    "token_reqs = wrapped.reset()\n",
    "print(\"TokenRequest keys:\", sorted(token_reqs[0].keys()))\n",
    "print(\"prompt:\", token_reqs[0][\"prompt\"], \"| messages_in_prompt:\", len(token_reqs[0][\"messages\"]))\n",
    "\n",
    "token_reqs = wrapped.step({token_reqs[0][\"actor\"]: \"<action>A</action>\"})\n",
    "print(\"step reward:\", token_reqs[0][\"reward\"])\n",
    "print(\"prompt:\", token_reqs[0][\"prompt\"], \"| messages_in_prompt:\", len(token_reqs[0][\"messages\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93192a0",
   "metadata": {},
   "source": [
    "## 4) Vectorization (multi-world batching)\n",
    "\n",
    "Vectorization is just \u201cmore actors\u201d: each env copy gets its own `env_id`.\n",
    "This uses the same API as multi-agent envs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3af127d",
   "metadata": {},
   "outputs": [],
   "source": [
    "venv = vectorize(lambda: TftIpdEnv(num_turns=1), num_envs=4)\n",
    "reqs = venv.reset()\n",
    "print(\"actors:\", [r[\"actor\"] for r in reqs])\n",
    "\n",
    "actions = {r[\"actor\"]: \"<action>A</action>\" for r in reqs}\n",
    "reqs2 = venv.step(actions)\n",
    "print(\"step rewards:\", {r[\"actor\"]: r[\"reward\"] for r in reqs2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d71eab8",
   "metadata": {},
   "source": [
    "## 5) Dual-mode hosting (in-memory vs out-of-process)\n",
    "\n",
    "The same env can be used:\n",
    "- in-process: `env = TftIpdEnv(...)`\n",
    "- out-of-process: `env = subprocess_env(...)`\n",
    "- in Docker: `env = docker_env(image=..., env=..., env_kwargs=...)` (same client API; image must have `gyllm` installed, e.g. `uv pip install gyllm`)\n",
    "\n",
    "Out-of-process is useful for isolation and for matching the \u201cenv in a container\u201d deployment style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73b847a",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote = subprocess_env(\n",
    "    env=\"gyllm.envs.simple.iterated_games:TftIpdEnv\",\n",
    "    env_kwargs={\"num_turns\": 1},\n",
    ")\n",
    "print(\"remote actors:\", remote.actors)\n",
    "reqs = remote.reset()\n",
    "reqs2 = remote.step({reqs[0][\"actor\"]: \"<action>A</action>\"})\n",
    "print(\"remote reward:\", reqs2[0][\"reward\"])\n",
    "remote.close()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}